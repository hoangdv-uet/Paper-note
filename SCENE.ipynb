{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE : A Scalable Two-Stage Personalized News Recommendation System\n",
    "\n",
    "**Contribute**:\n",
    "\n",
    "Propose a Scalable two-stage Personalize news recommendation approach with a two-level representation\n",
    "* First level consist various topics relevant to users’ preference and divide into group\n",
    "* 2$^{nd}$ level includes specific news articles and recommend news items\n",
    "\n",
    "\n",
    "Principled framework for news selection good balance between the novelty and diversity\n",
    "\n",
    "Multi-factor high-quality user profile construction\n",
    "\n",
    "**SCENE**: Consists of 3 Major components:\n",
    "* Newly-Published News Articles Clustering\n",
    "  * Partition newly published news into small groups by **Locality Sensitive Hashing**\n",
    "  * Hierarchically separate groups with average-link. Then LM **Probabilistic Latent Semantic Indexing** (PLSI) and **Latent Dirichlet Allocation** (LDA) applied to summarizing news articles\n",
    "* User Profile Contruction\n",
    "  * Constructed in: News topic distribution, Similar access patterns and news entity preference (which are all extracted from user's read history)\n",
    "* Personalized News Items Recommendation\n",
    "  * Compare the topic distributions of cluster and news content\n",
    "  * Then sequentially select the clusters based on Similarity ($1^{st}$ level)\n",
    "  * Continue compare Similarities of small news group and user's accesed news content (most similar groups as $2^{nd}$ level)\n",
    "  * In the most similar groups are model personalized news recommendation by greedy way \n",
    "## Recommendation Framework\n",
    "\n",
    "![image](SCENE_Framework1.png)\n",
    "\n",
    "\n",
    "## Methods in Framework\n",
    "### News article clustering\n",
    "* Decompose news articles to shingles \n",
    "  * Preprocessing: remove stop words, tokenize and stemm \n",
    "  * Shingling articles with $k = 10$ into matrix $M$ with rows is shingles and columns is articles\n",
    "* MinHasing\n",
    "  * Contruct Randomized 100 length Minhash signature \n",
    "* Locality Sensitive Hashing\n",
    "  * Signatures are initally decomposed into multiple bands, then use standard hash function  to hash into a big hash table (band length  = 5)\n",
    "  * Then separated news corpus into small news groups by Jaccard-based\n",
    "\n",
    "### News topic Detection\n",
    "* Detecting topics of a text corpus done by using probabilistic language models as  PLSI or LDA, by extracting a list of represent words from corpus. \n",
    "\n",
    "### User Profile Contruction\n",
    "* Built by eploration on: News content, Similar access patterns and preferred news entities\n",
    "  * Each User profile can be present : $\\mathcal{U =<T,P,E>}$\n",
    "    * $\\mathcal{T}$ represent topic distribution of news that user access in the past $\\mathcal{\\{<t_1, w_1>, <t_2, w_2>,...\\}}$ with corresponding weight\n",
    "    * $\\mathcal{P}$ represent list of user $<u_1, u_2,...>$ similar access pattens with given user\n",
    "    * $\\mathcal{E}$ represent list of named entities $<e_1, e_2, ...>$ from user's reading history\n",
    "  * **News content summarize** by use represent users’ reading history as the same as the representations for news groups\n",
    "  * **Access pattern** is built by calulating pairwise similarity between user given and orther user's reading history with Jacard-Sim. Similarity score is predefined by theshold.\n",
    "  * **Name entities** is built by NLP task. \"Each news article is associated with a list of named entities along with their corresponding entity types\"\n",
    "  \n",
    "### Personalized Recommendation\n",
    "  #### Interest Matching for Representation Lv.1\n",
    "  * Ranking by cosine similarity between topic distribution of each cluster $\\mathcal{T_C}$ and user’s profile $\\mathcal{T_U}$\n",
    "  * Choose the clusters with the score greater than dynamic threshold\n",
    "  * Dig into each cluster and choose the news group most similar to the user’s interest\n",
    "  #### News Selection for Representation Lv.2\n",
    "  * **News Profile** helpful to compare two news, and evaluate how the news item can satisfy the user’s reading preference\n",
    "    * News profile $\\mathcal{F_n = <T_n, P_n, E_n>}$ and User's profile $\\mathcal{F_u = <T_u, P_u, E_u>}$, and Similarity of them is computed:\n",
    "  $$\\mathcal{Sim(F_n, F_u) = \\frac{\\alpha Sim(T_n,T_u) + \\beta Sim(P_n, P_u) + \\gamma Sim(E_n, E_u)}{\\sqrt{\\alpha^2 + \\beta^2 + \\gamma^2}}}$$\n",
    "  Where ${\\alpha, \\beta, \\gamma}$ are parameters to control how we trust the corresponding components\n",
    "    \n",
    "  $Sim(T_n,T_u)$ is computed by Cosin similarity\n",
    "  \n",
    "  $Sim(P_n, P_u), Sim(E_n, E_u)$ is computed by Jaccard similarity\n",
    "  \n",
    "  #### Submodularity\n",
    "  Tyically, a news reader is not interested all of aspects in the given topic. So, news selection strategy can be described as follows:\n",
    "  ( $\\mathcal{N}$ is original news group, $\\mathcal{S}$ is selected news set, $\\mathcal{\\zeta}$ is the news being selected ). \n",
    "  \n",
    "  After selecting $\\zeta$:\n",
    "  * $S$ should be similar to the general topic in $N\\ \\backslash S$;\n",
    "  * The topic  topic diversity should not deviate much in $S$;\n",
    "  * $S$ should provide more satisfaction to the given user’s reading preference\n",
    "  \n",
    "  Quality function $f$ to evaluate the news set $S$:\n",
    "  $$\n",
    "  \\mathcal{ f(S) = \\frac{1}{|N \\backslash S|.|S|}\\sum_{n_1\\in N \\backslash S }{\\sum_{n_2 \\in S}{sim(n_1, n_2)}} + \\frac{1}{(\\begin{aligned}\n",
    "  |S| \\\\ 2\n",
    "  \\end{aligned})} \\sum_{\\begin{aligned}\n",
    "    n_1,n_2 \\in S \\\\\n",
    "    n_1 \\neq n_2\n",
    "  \\end{aligned}}{-sim(n_1,n_2)} + \\frac{1}{|S|} \\sum_{n_1 \\in S}{sim(u, n_1)}\n",
    "  }$$ \n",
    "  $n_1$ and $n_2$ denote news items, $u$ denote given user\n",
    "\n",
    "  Three components are involved:\n",
    "  * The first one aims to evaluate the quality of selected news set $\\mathcal S$ over original\n",
    "  * The second one provides a perspective on how diverse that the top- ics underlying the selected news articles\n",
    "  * The last one is evidence that how much the user’s preference is satisfied by $\\mathcal S$ \n",
    "  \n",
    "  #### Ranking Adjustment\n",
    "  The ranking of the selected news articles(popularity and recency) need to be adjusted for more reasonable by normalized two types of properties\n",
    "\n",
    "  Given $\\mathcal n$, the popularity $\\mathcal n_P$ and the recency $\\mathcal n_I$ can be combined as\n",
    "  $$n_\\phi = \\frac{n_P-n_{P_{min}}}{n_{p_{max}}- n_{p_{min}} } - \\frac{n_I - n_{I_{min}}}{n_{I_{max}} - n_{I_{min}}}.$$\n",
    "\n",
    "  Recency is restricted by time\n",
    "\n",
    "  The generated ranking can emphasize more popular and fresh news items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
